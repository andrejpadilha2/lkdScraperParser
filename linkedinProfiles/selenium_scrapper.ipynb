{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from time import sleep\n",
    "from timeit import default_timer as timer\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium_stealth import stealth\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from utils.generate_name_variations import generate_name_variations\n",
    "from utils.methods import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_studied_at_universities(page_source, universities_to_check):\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # Find the script tag containing the JSON-LD data\n",
    "    script = soup.find('script', type='application/ld+json')\n",
    "\n",
    "    if script:\n",
    "        # Extract the JSON content\n",
    "        json_data = script.string\n",
    "        print(f\"json data: {json_data}\")\n",
    "\n",
    "        # Parse the JSON content\n",
    "        data = json.loads(json_data)\n",
    "        print(f\"data: {data}\")\n",
    "\n",
    "        try:\n",
    "            # Check if the person studied at any of the specified universities\n",
    "            alumni_of = data['@graph'][0]['alumniOf']\n",
    "            print(f\"alumni of: {alumni_of}\")\n",
    "            universities_studied = [org['name'] for org in alumni_of if org['@type'] == 'EducationalOrganization']\n",
    "            print(f\"universities: {universities_studied}\")\n",
    "\n",
    "            for university_to_check in universities_to_check:\n",
    "                for university_studied in universities_studied:\n",
    "                    if university_to_check in university_studied:\n",
    "                        return True\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_page_problems(page_source):\n",
    "    problems = \"\"\n",
    "    success = 1\n",
    "\n",
    "    if \"authwall\" in page_source:\n",
    "        print(\"→ You hit the authentication wall!\")\n",
    "        problems = \"authwall_\"\n",
    "        success = 0\n",
    "\n",
    "    if \"captcha\" in page_source:\n",
    "        print(\"→ You hit a captcha page!\")\n",
    "        problems += \"captcha_\"\n",
    "        success = 0\n",
    "\n",
    "    if page_source.startswith(\"<html><head>\\n    <script type=\\\"text/javascript\\\">\\n\"):\n",
    "        print(\"→ You hit javascript obfuscated code!\")\n",
    "        problems += \"obfuscatedJS_\"\n",
    "        success = 0\n",
    "    \n",
    "    return problems, success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_webdriver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    options.add_argument('--blink-settings=imagesEnabled=false')\n",
    "    # options.add_argument(\"--headless\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.implicitly_wait(60)\n",
    "    stealth(driver,\n",
    "            languages=[\"en-US\", \"en\"],\n",
    "            vendor=\"Google Inc.\",\n",
    "            platform=\"Win32\",\n",
    "            webgl_vendor=\"Intel Inc.\",\n",
    "            renderer=\"Intel Iris OpenGL Engine\",\n",
    "            fix_hairline=True)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ sleeping 1 second...\n",
      "→ Requesting 'www.google.com.br'.\n",
      "→ sleeping between 1 and 2 seconds...\n",
      "→ Searching on Google.\n",
      "→ sleeping between 2 and 3 seconds...\n",
      "['gabriela', 'bertoni', 'dos', 'santos']\n",
      "['gabriela', 'bertoni', 'dos', 'santos']\n",
      "True\n",
      "→ Requesting 'https://de.linkedin.com/in/gabrielabertoni/pt'.\n",
      "→ sleeping between 5 and 7 seconds...\n"
     ]
    }
   ],
   "source": [
    "full_name = 'Gabriela Bertoni dos Santos'\n",
    "name_variation = 'Gabriela Bertoni dos Santos'\n",
    "\n",
    "\n",
    "driver = initialize_webdriver()\n",
    "sleep(1, '→ sleeping 1 second...')\n",
    "\n",
    "print(\"→ Requesting 'www.google.com.br'.\")\n",
    "driver.get('https://www.google.com.br')\n",
    "sleep(random.uniform(1, 2), '→ sleeping between 1 and 2 seconds...')\n",
    "\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "search_query = f\"{name_variation} ufabc linkedin\"\n",
    "print(\"→ Searching on Google.\")\n",
    "search_box.send_keys(search_query)\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "sleep(random.uniform(2, 3), '→ sleeping between 2 and 3 seconds...')\n",
    "links = driver.find_elements(By.TAG_NAME, 'a')\n",
    "linkedin_links = [link for link in links if link.get_attribute('href') and 'linkedin.com/in/' in link.get_attribute('href')]\n",
    "\n",
    "if linkedin_links:               \n",
    "    linkedin_url = linkedin_links[0].get_attribute('href').split(\"?\")[0] # we only consider the first linkedin profile\n",
    "\n",
    "    linkedin_link_title = linkedin_links[0].text.split()\n",
    "    hyphen_index = linkedin_link_title.index('-')\n",
    "\n",
    "    names_in_linkedin_link = linkedin_link_title[:hyphen_index]\n",
    "    names_in_linkedin_link = [normalize_string(name) for name in names_in_linkedin_link]\n",
    "    print(names_in_linkedin_link)\n",
    "\n",
    "    names_in_full_name = full_name.split()\n",
    "    names_in_full_name = [normalize_string(name) for name in names_in_full_name]\n",
    "    print(names_in_full_name)\n",
    "\n",
    "    is_subset = set(names_in_linkedin_link) <= set(names_in_full_name)\n",
    "    print(is_subset)\n",
    "\n",
    "    first_name_name_variation = normalize_string(name_variation.split()[0].lower())\n",
    "\n",
    "    if not is_subset:\n",
    "        print(f\"→ Names of Linkedin profile are not a subset of real full name, skipping...\")\n",
    "    else:\n",
    "        print(f\"→ Requesting '{linkedin_url}'.\")\n",
    "        linkedin_links[0].click()\n",
    "        sleep(random.uniform(5, 7), '→ sleeping between 5 and 7 seconds...')\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        problems, success = check_page_problems(page_source) \n",
    "        # TODO\n",
    "        # If it's the xth unsucessful reply in a row, do something\n",
    "        driver.close()      \n",
    "else:\n",
    "    print(\"→ No LinkedIn search results to access.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "University: FH Campus Wien | University of Applied Sciences\n",
      "Degree Info: ['Master of Science in Engineering (MSc)', 'Packaging Technology and Sustainability']\n",
      "Duration: 2022 - o momento\n",
      "Details: None\n",
      "---\n",
      "University: Universidade Federal do ABC\n",
      "Degree Info: ['Bacharelado em Engenharia', 'Engenharia de Materiais', '3,92 de 4']\n",
      "Duration: 2013 - 2019\n",
      "Details: Caracterização e avaliação do desempenho de materiais, propriedades dos materiais, processamento de materiais, nanociência e nanotecnologia dos materiais.\n",
      "---\n",
      "University: Offenburg University of Applied Sciences\n",
      "Degree Info: ['Bacharelado em Engenharia', 'Engenharia Mecânica e Engenharia de Materiais']\n",
      "Duration: 2018 - 2018\n",
      "Details: Mobilidade acadêmica para a Hochschule Offenburg, como bolsista da Fundação Baden-Württemberg.\n",
      "---\n",
      "University: TU Dortmund University\n",
      "Degree Info: ['International Summer Program']\n",
      "Duration: 2017 - 2017\n",
      "Details: Cursos: German Culture and Society, German Language, International Business and Industrial Marketing\n",
      "---\n",
      "University: Universidade Federal do ABC\n",
      "Degree Info: ['Bacharelado em Ciência e Tecnologia', 'Ciência e Tecnologia', '3,90 out of 4']\n",
      "Duration: 2013 - 2017\n",
      "Details: Ciência da Computação, Ciências Naturais, Ciências da Engenharia, Física e Matemática\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    # TODO\n",
    "    # 3) check if the person studied at UFABC\n",
    "    studied_at_ufabc = False\n",
    "\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "    # Find the script tag containing the JSON-LD data\n",
    "    education_items = soup.find_all('li', class_='education__list-item')\n",
    "\n",
    "    # print(education_items)\n",
    "\n",
    "\n",
    "    for item in education_items:\n",
    "        # TODO\n",
    "        # extract activities and groups that the person participated\n",
    "\n",
    "        university_element = item.find('h3', class_='profile-section-card__title')\n",
    "        university = university_element.text.strip() if university_element else None\n",
    "        \n",
    "        degree_info_elements = item.find_all('span', class_='education__item--degree-info')\n",
    "        degree_info = [degree_info_element.text.strip() for degree_info_element in degree_info_elements]\n",
    "        \n",
    "        duration_element = item.find('p', class_='education__item--duration')\n",
    "        duration = duration_element.text.strip() if duration_element else None\n",
    "\n",
    "        details_element = item.find('div', class_='show-more-less-text')\n",
    "        details = details_element.text.strip() if details_element else None\n",
    "\n",
    "        # Print the extracted information\n",
    "        print('University:', university)\n",
    "        print('Degree Info:', degree_info)\n",
    "        print('Duration:', duration)\n",
    "        print('Details:', details)\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkedin_scrapper",
   "language": "python",
   "name": "linkedin_scrapper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "835a58a9326911df0cc25148838ba18195d724fb2eaa1b48a6b9900a4baac6e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
